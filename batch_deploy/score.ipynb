{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e84abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b30e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e0ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.pipeline.prediction import PredictionPipeline\n",
    "import pandas as pd\n",
    "from copy import deepcopy as dc\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca9d81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘batch_deploy/output’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir batch_deploy/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c77e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"artifacts/data_transformation/test.csv\"\n",
    "output_file = \"batch_deploy/output/rainfall_preds.parquet\"\n",
    "RUN_ID = os.getenv(\"RUN_ID\", \"8de0cb304e844db8ae045f16c26c71db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "376193f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename: str):\n",
    "    data = pd.read_csv(filename, index_col=\"time\")\n",
    "    features = data.drop(columns=[\"is_rain\", \"rainfall\"])\n",
    "    \n",
    "    target = data[\"rainfall\"].values\n",
    "    \n",
    "    return features, target\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f741bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = read_data(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd7df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "        def __init__(self, X, y):\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "        def     __getitem__(self, i):\n",
    "            return self.X[i], self.y[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba083dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, output_file):\n",
    "    results.to_parquet(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "087f1d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_df, y_test, run_id, output_file):\n",
    "    model_object = PredictionPipeline(run_id=run_id)\n",
    "    \n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    # Scale features\n",
    "    X_test = X_df.values\n",
    "    X_test_scaled = model_object.scaler.transform(X_test)\n",
    "    classifier_preds = model_object.classifier.predict(X_test_scaled)\n",
    "\n",
    "    # Prepare LSTM input\n",
    "    X_test_lstm = dc(np.flip(X_test_scaled, axis=1))\n",
    "    vars_dim = X_test_lstm.shape[1]\n",
    "    X_test_lstm = X_test_lstm.reshape((-1, vars_dim, 1))\n",
    "    X_test_tensor = torch.tensor(X_test_lstm).float()\n",
    "    y_test_tensor = torch.tensor(y_test).float()\n",
    "    \n",
    "    test_dataset = TimeSeriesDataset(X_test_tensor, y_test_tensor)\n",
    "    batch_size = 8\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model  = model_object.regressor\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i, (X_batch, _) in enumerate(test_loader):\n",
    "            X_batch = X_batch.to(device)\n",
    "            \n",
    "            # If classifier said 0 → output 0\n",
    "            clf_batch_preds = classifier_preds[i * batch_size : (i + 1) * batch_size]\n",
    "            batch_preds = []\n",
    "            if len(clf_batch_preds) < len(X_batch):\n",
    "                # Handle last smaller batch\n",
    "                X_batch = X_batch[:len(clf_batch_preds)]\n",
    "            \n",
    "            for j, clf_pred in enumerate(clf_batch_preds):\n",
    "                if clf_pred == 0:\n",
    "                    batch_preds.append(0.0)\n",
    "                else:\n",
    "                    reg_out = model(X_batch[j].unsqueeze(0))\n",
    "                    batch_preds.append(reg_out[0].item())\n",
    "            \n",
    "            predictions.extend(batch_preds)\n",
    "\n",
    "    predictions = np.array(predictions).reshape(-1, 1)\n",
    "    \n",
    "    n = len(X_df)\n",
    "    rainfall_ids = []\n",
    "    for _ in range(n):\n",
    "        rainfall_ids.append(str(uuid.uuid4()))  \n",
    "        \n",
    "    \n",
    "    df_results = dc(X_df)\n",
    "    df_results.insert(0, \"rainfall_id\", rainfall_ids)\n",
    "    df_results.loc[:, \"rainfall_actual\"] = y_test\n",
    "    df_results.loc[:, \"rainfall_predicted\"] = predictions\n",
    "    df_results.loc[:, \"diff\"] = df_results[\"rainfall_actual\"] - df_results[\"rainfall_predicted\"]\n",
    "    df_results.loc[:, \"model_version\"] = run_id\n",
    "    \n",
    "    \n",
    "    save_results(df_results, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a01f1081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 31.54it/s]\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 17.63it/s]\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 27.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict(X_df=X_test, y_test=y_test, run_id=RUN_ID, output_file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6dd08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b08dece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8d7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2d1db6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rain-pred",
   "language": "python",
   "name": "rain-pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
